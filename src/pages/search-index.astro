---
import { MarkdownInstance } from "astro"
import fs from "node:fs"

// import .astro files
const pages = await Astro.glob("./**/*.astro")

// import .md files
//const posts = [...(await Astro.glob("./**/*.md")).filter((post) => !post.frontmatter.draft)]
const postsMdx = [...(await Astro.glob("../content/**/*.mdx")).filter((post) => !post.frontmatter.draft)]
const postsMdxWithContent = postsMdx.map((post) => {
  const url = new URL(post.file, import.meta.url)
  var content = fs.readFileSync(url, "utf-8")

  // Temp fix for Algolia record size limits: Limit record size with .substring()
  if (content.length > 78000) {
    content = content.substring(0, 78000)
    console.warn("\x1b[1;43mRecord exceeds 78000 chars and was trimmed - " + url + "\x1b[0m")
  }
  return { ...post, rawContent: () => content }
})

const markDownFiles = [...postsMdxWithContent]

//const allContent = [...pages, ...postsMdx]

const transformMarkdownInstancesToIndexes = async (instances: MarkdownInstance<Record<string, any>>[]) => {
  return Promise.all(
    instances.map(async (instance) => {
      const { title, section, metadata } = instance.frontmatter
      const headings = await instance.getHeadings()
      const content = !!instance.rawContent ? await instance.rawContent() : undefined

      return {
        title,
        headings,
        url: instance.url,
        section,
        description: metadata?.description ?? undefined,
        content,
      }
    })
  )
}

const index = await transformMarkdownInstancesToIndexes(markDownFiles)

const stringifiedJson = JSON.stringify({ index }, null, 2)

fs.writeFileSync(`${process.cwd()}/public/search-index.json`, stringifiedJson)
---

<meta http-equiv="refresh" content={`0; url=/`} />
